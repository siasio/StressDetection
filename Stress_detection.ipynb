{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0upsp9judfq"
      },
      "source": [
        "Library for sound processing with the Wav2Vec2 models: https://github.com/jonatasgrosman/huggingsound <br>\n",
        "API of the Russian National Corpus: https://github.com/kunansy/RNC <br>\n",
        "Not fine-tuned large Wav2Vec2 model pretrained on common_voice dataset for 53 languages: \"facebook/wav2vec2-large-xlsr-53\"<br>\n",
        "Fine-tuned Wav2Vec2 model which is most probably useless for us because it uses a token set containing characters of the cyrillic alphabet and we want to also use tokens which mark the lexical stress: \"jonatasgrosman/wav2vec2-large-xlsr-53-russian\"<br>\n",
        "Training arguments (might be useful for performing ablation studies): https://huggingface.co/transformers/v4.4.2/_modules/transformers/training_args.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZkKRaECVwVr"
      },
      "source": [
        "# Mount Google drive\n",
        "Mounting google drive is necessary for working with files saved there. I shared the folder with RNC data with you. To work with the data folder, go to the \"Shared with me\" folder on your google drive, right-click on the RussianNationalCorpus and press \"Add shortcut to Drive\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jY0oHFoll87",
        "outputId": "61c3121d-c09c-4f1f-f1b2-40ecd74ad1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "DATA_PATH = \"/content/drive/MyDrive/RussianNationalCorpus\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxaOaK9BJxlp",
        "outputId": "338e9d04-3496-4329-cb12-3b9922dd584f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StressDetection'...\n",
            "remote: Enumerating objects: 177, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 177 (delta 2), reused 6 (delta 1), pack-reused 165\u001b[K\n",
            "Receiving objects: 100% (177/177), 177.07 KiB | 1.86 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/siasio/StressDetection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtQH-2A8Jvw2"
      },
      "outputs": [],
      "source": [
        "DOWNLOADING_PATH = '/content/StressDetection/download_examples.py'\n",
        "CLEANING_PATH = '/content/StressDetection/clean_csv.py'\n",
        "TRAINING_PATH = '/content/StressDetection/run_training.py'\n",
        "EVALUATION_PATH = '/content/StressDetection/evaluate_model.py'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVPjsx8hV64a"
      },
      "source": [
        "# pip install libraries rnc and hugging sound\n",
        "Attention: after installing the hugginsound library, you will most probably need to change a library file called trainer.py. In colab you will find it located in usr/local/lib/python3.7/dist-packages/hugginsound/trainer.py (to find the usr folder, open the file browser in the left panel and press two dots above the sample_data folder to reach the root directory). The change you need to make, is replacing self.use_amp with self.use_cuda_amp in lines 434 and 451.\n",
        "\n",
        "After making the changes, you need to reinstall the library. In colab, you need to restart runtime first and then run the pip install command again.\n",
        "\n",
        "Making the changes is not required if you only want to run the evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sSIJ-OayjEZ",
        "outputId": "c644676f-f453-4b12-a3c0-62bb347b1049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rnc\n",
            "  Downloading rnc-0.10.0-py3-none-any.whl (37 kB)\n",
            "Collecting types-aiofiles<0.9.0,>=0.8.4\n",
            "  Downloading types_aiofiles-0.8.11-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: bs4<0.1.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from rnc) (0.0.1)\n",
            "Requirement already satisfied: lxml<4.10.0,>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from rnc) (4.9.2)\n",
            "Collecting beautifulsoup4<4.12.0,>=4.11.1\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<3.9.0,>=3.8.1 in /usr/local/lib/python3.8/dist-packages (from rnc) (3.8.4)\n",
            "Collecting aiofiles<0.9.0,>=0.8.0\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Collecting ujson<5.5.0,>=5.4.0\n",
            "  Downloading ujson-5.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-ujson<5.5.0,>=5.4.0\n",
            "  Downloading types_ujson-5.4.0-py3-none-any.whl (2.2 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<3.9.0,>=3.8.1->rnc) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<3.9.0,>=3.8.1->rnc) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<3.9.0,>=3.8.1->rnc) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<3.9.0,>=3.8.1->rnc) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp<3.9.0,>=3.8.1->rnc) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<3.9.0,>=3.8.1->rnc) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<3.9.0,>=3.8.1->rnc) (6.0.4)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.9.0,>=3.8.1->rnc) (2.10)\n",
            "Installing collected packages: types-ujson, types-aiofiles, ujson, soupsieve, aiofiles, beautifulsoup4, rnc\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed aiofiles-0.8.0 beautifulsoup4-4.11.2 rnc-0.10.0 soupsieve-2.4 types-aiofiles-0.8.11 types-ujson-5.4.0 ujson-5.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting huggingsound\n",
            "  Downloading huggingsound-0.1.6-py3-none-any.whl (28 kB)\n",
            "Collecting transformers<5.0.0,>=4.23.1\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiwer<3.0.0,>=2.5.1\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting datasets<3.0.0,>=2.6.1\n",
            "  Downloading datasets-2.10.0-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting librosa<0.10.0,>=0.9.2\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch!=1.12.0,<1.13.0,>=1.7\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (1.3.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (2.25.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (2023.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (1.22.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound) (3.8.4)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (0.12.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (1.2.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (1.6.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (1.7.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,<1.13.0,>=1.7->huggingsound) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound) (2022.6.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound) (3.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa<0.10.0,>=0.9.2->huggingsound) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa<0.10.0,>=0.9.2->huggingsound) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa<0.10.0,>=0.9.2->huggingsound) (6.0.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa<0.10.0,>=0.9.2->huggingsound) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound) (1.24.3)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->librosa<0.10.0,>=0.9.2->huggingsound) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>=0.9.2->huggingsound) (1.15.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets<3.0.0,>=2.6.1->huggingsound) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets<3.0.0,>=2.6.1->huggingsound) (2022.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>=0.9.2->huggingsound) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets<3.0.0,>=2.6.1->huggingsound) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.45.1->librosa<0.10.0,>=0.9.2->huggingsound) (3.14.0)\n",
            "Installing collected packages: tokenizers, xxhash, urllib3, torch, rapidfuzz, multiprocess, levenshtein, responses, jiwer, huggingface-hub, transformers, librosa, datasets, huggingsound\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.10.0 huggingface-hub-0.12.1 huggingsound-0.1.6 jiwer-2.5.1 levenshtein-0.20.2 librosa-0.9.2 multiprocess-0.70.14 rapidfuzz-2.13.7 responses-0.18.0 tokenizers-0.13.2 torch-1.12.1 transformers-4.26.1 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install rnc\n",
        "!pip install huggingsound"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtBXiOEWXeHq"
      },
      "source": [
        "# Download samples if they are not downloaded yet\n",
        "Perhaps, we need to import the nest_asyncio library. Without it, colab has problems with managing nested asynchronous processes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piFI2najikGD",
        "outputId": "0e32df61-7cd2-469d-8f41-02dcae9cfe86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nest_asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: nest_asyncio\n",
            "Successfully installed nest_asyncio-1.5.6\n"
          ]
        }
      ],
      "source": [
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZvplF6Xikju",
        "outputId": "c52a5c4f-854c-418c-840b-754fb1cf8b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/StressDetection\n"
          ]
        }
      ],
      "source": [
        "%cd StressDetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFbYH9vIynJt",
        "outputId": "91fd1b3c-ca78-482e-8914-668acdbc1046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: download_examples.py\n",
            "       [-h]\n",
            "       [--config CONFIG]\n",
            "       [--eval]\n",
            "       words\n",
            "       [words ...]\n",
            "\n",
            "positional arguments:\n",
            "  words\n",
            "    List of the\n",
            "    words to\n",
            "    query the\n",
            "    Russian\n",
            "    National\n",
            "    Corpus for.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --config CONFIG\n",
            "    Path to the\n",
            "    config file\n",
            "    (should be\n",
            "    located in\n",
            "    the config\n",
            "    folder).\n",
            "  --eval\n",
            "    Whether to\n",
            "    save the\n",
            "    downloaded\n",
            "    data in an\n",
            "    eval csv\n"
          ]
        }
      ],
      "source": [
        "!python $DOWNLOADING_PATH --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwQzrkX6LGjQ",
        "outputId": "495b29ae-0fb2-4fdc-f444-bd58dd7d87ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: clean_csv.py\n",
            "       [-h]\n",
            "       [--config CONFIG]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --config CONFIG\n",
            "    Path to the\n",
            "    config file\n",
            "    (should be\n",
            "    located in\n",
            "    the config\n",
            "    folder).\n"
          ]
        }
      ],
      "source": [
        "!python $CLEANING_PATH --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL-YGEGCXxyZ"
      },
      "source": [
        "# Run training\n",
        "Run first the --help command to learn which arguments you should provide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0TAKYmd9IhQ"
      },
      "outputs": [],
      "source": [
        "# !pip3 install torch==1.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXRB3Q6xgMmg"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp_h5aaquYDQ",
        "outputId": "4a8ce376-9da9-4215-e1cc-5c49c967d906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-24 11:52:46.184490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-24 11:52:47.305053: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-24 11:52:47.305167: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-24 11:52:47.305185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "INFO:huggingsound.speech_recognition.model:Loading model...\n",
            "INFO:rnc:Requested to 'https://processing.ruscorpora.ru/search.xml' [0;1) with params {'env': 'alpha', 'api': '1.0', 'lang': 'ru', 'dpp': 5, 'spd': 10, 'text': 'lexform', 'out': 'normal', 'sort': 'i_grtagging', 'nodia': 0, 'req': 'сходить', 'lex1': 'сходить', 'mode': 'murco'}\n",
            "DEBUG:rnc:Worker-1: Requested to 'https://processing.ruscorpora.ru/search.xml' with '{'env': 'alpha', 'api': '1.0', 'lang': 'ru', 'dpp': 5, 'spd': 10, 'text': 'lexform', 'out': 'normal', 'sort': 'i_grtagging', 'nodia': 0, 'req': 'сходить', 'lex1': 'сходить', 'mode': 'murco', 'p': 0}'\n",
            "DEBUG:rnc:Worker-1: Received from 'https://processing.ruscorpora.ru/search.xml' with '{'env': 'alpha', 'api': '1.0', 'lang': 'ru', 'dpp': 5, 'spd': 10, 'text': 'lexform', 'out': 'normal', 'sort': 'i_grtagging', 'nodia': 0, 'req': 'сходить', 'lex1': 'сходить', 'mode': 'murco', 'p': 0}'\n",
            "INFO:rnc:Request was successfully completed\n",
            "INFO:rnc:Coro executing time: 0.49\n",
            "INFO:rnc:Requested to 'https://processing.ruscorpora.ru/search.xml' [0;1) with params {'env': 'alpha', 'api': '1.0', 'lang': 'ru', 'dpp': 5, 'spd': 10, 'text': 'lexform', 'out': 'normal', 'sort': 'i_grtagging', 'nodia': 0, 'req': 'показала', 'lex1': 'показала', 'mode': 'murco'}\n",
            "DEBUG:rnc:Worker-1: Requested to 'https://processing.ruscorpora.ru/search.xml' with '{'env': 'alpha', 'api': '1.0', 'lang': 'ru', 'dpp': 5, 'spd': 10, 'text': 'lexform', 'out': 'normal', 'sort': 'i_grtagging', 'nodia': 0, 'req': 'показала', 'lex1': 'показала', 'mode': 'murco', 'p': 0}'\n",
            "DEBUG:rnc:Worker-1: Received from 'https://processing.ruscorpora.ru/search.xml' with '{'env': 'alpha', 'api': '1.0', 'lang': 'ru', 'dpp': 5, 'spd': 10, 'text': 'lexform', 'out': 'normal', 'sort': 'i_grtagging', 'nodia': 0, 'req': 'показала', 'lex1': 'показала', 'mode': 'murco', 'p': 0}'\n",
            "INFO:rnc:Request was successfully completed\n",
            "INFO:rnc:Coro executing time: 0.44\n",
            "WARNING:root:blank_token <pad> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:silence_token | not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:unk_token <unk> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:bos_token <s> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:eos_token </s> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:huggingsound.speech_recognition.model:The model is already fine-tuned. So the provided token_set won't be used. The model's token_set will be used instead\n",
            "INFO:huggingsound.speech_recognition.model:Loading training data...\n",
            "INFO:huggingsound.speech_recognition.model:Loading data from cache...\n",
            "INFO:huggingsound.speech_recognition.model:Loading evaluation data...\n",
            "INFO:huggingsound.speech_recognition.model:Loading data from cache...\n",
            "INFO:huggingsound.speech_recognition.model:Starting fine-tuning process...\n",
            "INFO:huggingsound.trainer:Getting dataset stats...\n",
            "INFO:huggingsound.trainer:Training dataset size: 6168 samples, 19.540069913194586 hours\n",
            "INFO:huggingsound.trainer:Evaluation dataset size: 500 samples, 1.597156076388888 hours\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1639: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
            "  warnings.warn(\n",
            "INFO:huggingsound.trainer:Building trainer...\n",
            "Using cuda_amp half precision backend\n",
            "INFO:huggingsound.trainer:Starting training...\n",
            "Feature extractor saved in /content/model-cyrillic-stress/preprocessor_config.json\n",
            "tokenizer config file saved in /content/model-cyrillic-stress/tokenizer_config.json\n",
            "Special tokens file saved in /content/model-cyrillic-stress/special_tokens_map.json\n",
            "Loading model from /content/model-cyrillic-stress.\n",
            "The following columns in the training set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 6168\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 12\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 1542\n",
            "  Number of trainable parameters = 311267494\n",
            "  0% 0/1542 [00:00<?, ?it/s]Didn't find an RNG file, if you are resuming a training that was launched in a distributed fashion, reproducibility is not guaranteed.\n",
            "{'loss': 1400.3663, 'learning_rate': 4.785992217898833e-06, 'epoch': 0.19}\n",
            "{'loss': 1316.9989, 'learning_rate': 1.0622568093385214e-05, 'epoch': 0.39}\n",
            "{'loss': 1369.5988, 'learning_rate': 1.6342412451361866e-05, 'epoch': 0.58}\n",
            "{'loss': 1356.8447, 'learning_rate': 2.2178988326848252e-05, 'epoch': 0.78}\n",
            "{'loss': 1334.3091, 'learning_rate': 2.801556420233463e-05, 'epoch': 0.97}\n",
            " 16% 250/1542 [34:58<1:36:23,  4.48s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/63 [00:01<00:41,  1.46it/s]\u001b[A\n",
            "  5% 3/63 [00:02<00:59,  1.01it/s]\u001b[A\n",
            "  6% 4/63 [00:04<01:13,  1.25s/it]\u001b[A\n",
            "  8% 5/63 [00:06<01:19,  1.38s/it]\u001b[A\n",
            " 10% 6/63 [00:07<01:17,  1.36s/it]\u001b[A\n",
            " 11% 7/63 [00:08<01:15,  1.35s/it]\u001b[A\n",
            " 13% 8/63 [00:10<01:14,  1.35s/it]\u001b[A\n",
            " 14% 9/63 [00:11<01:14,  1.38s/it]\u001b[A\n",
            " 16% 10/63 [00:13<01:16,  1.44s/it]\u001b[A\n",
            " 17% 11/63 [00:14<01:18,  1.51s/it]\u001b[A\n",
            " 19% 12/63 [00:16<01:19,  1.56s/it]\u001b[A\n",
            " 21% 13/63 [00:18<01:19,  1.59s/it]\u001b[A\n",
            " 22% 14/63 [00:19<01:15,  1.55s/it]\u001b[A\n",
            " 24% 15/63 [00:21<01:14,  1.55s/it]\u001b[A\n",
            " 25% 16/63 [00:22<01:13,  1.56s/it]\u001b[A\n",
            " 27% 17/63 [00:24<01:10,  1.53s/it]\u001b[A\n",
            " 29% 18/63 [00:25<01:07,  1.51s/it]\u001b[A\n",
            " 30% 19/63 [00:27<01:06,  1.52s/it]\u001b[A\n",
            " 32% 20/63 [00:28<01:05,  1.53s/it]\u001b[A\n",
            " 33% 21/63 [00:30<01:05,  1.55s/it]\u001b[A\n",
            " 35% 22/63 [00:31<01:03,  1.56s/it]\u001b[A\n",
            " 37% 23/63 [00:33<01:01,  1.54s/it]\u001b[A\n",
            " 38% 24/63 [00:34<01:00,  1.54s/it]\u001b[A\n",
            " 40% 25/63 [00:36<00:58,  1.54s/it]\u001b[A\n",
            " 41% 26/63 [00:37<00:55,  1.50s/it]\u001b[A\n",
            " 43% 27/63 [00:39<00:54,  1.51s/it]\u001b[A\n",
            " 44% 28/63 [00:40<00:51,  1.48s/it]\u001b[A\n",
            " 46% 29/63 [00:42<00:51,  1.51s/it]\u001b[A\n",
            " 48% 30/63 [00:43<00:48,  1.46s/it]\u001b[A\n",
            " 49% 31/63 [00:45<00:45,  1.41s/it]\u001b[A\n",
            " 51% 32/63 [00:46<00:45,  1.47s/it]\u001b[A\n",
            " 52% 33/63 [00:48<00:45,  1.51s/it]\u001b[A\n",
            " 54% 34/63 [00:49<00:43,  1.49s/it]\u001b[A\n",
            " 56% 35/63 [00:51<00:40,  1.46s/it]\u001b[A\n",
            " 57% 36/63 [00:52<00:39,  1.47s/it]\u001b[A\n",
            " 59% 37/63 [00:54<00:38,  1.48s/it]\u001b[A\n",
            " 60% 38/63 [00:55<00:38,  1.53s/it]\u001b[A\n",
            " 62% 39/63 [00:57<00:36,  1.51s/it]\u001b[A\n",
            " 63% 40/63 [00:58<00:35,  1.56s/it]\u001b[A\n",
            " 65% 41/63 [01:00<00:34,  1.59s/it]\u001b[A\n",
            " 67% 42/63 [01:02<00:32,  1.55s/it]\u001b[A\n",
            " 68% 43/63 [01:03<00:30,  1.51s/it]\u001b[A\n",
            " 70% 44/63 [01:04<00:27,  1.42s/it]\u001b[A\n",
            " 71% 45/63 [01:06<00:26,  1.48s/it]\u001b[A\n",
            " 73% 46/63 [01:07<00:25,  1.51s/it]\u001b[A\n",
            " 75% 47/63 [01:09<00:24,  1.52s/it]\u001b[A\n",
            " 76% 48/63 [01:11<00:23,  1.57s/it]\u001b[A\n",
            " 78% 49/63 [01:12<00:21,  1.51s/it]\u001b[A\n",
            " 79% 50/63 [01:13<00:19,  1.53s/it]\u001b[A\n",
            " 81% 51/63 [01:15<00:18,  1.56s/it]\u001b[A\n",
            " 83% 52/63 [01:17<00:17,  1.55s/it]\u001b[A\n",
            " 84% 53/63 [01:18<00:15,  1.58s/it]\u001b[A\n",
            " 86% 54/63 [01:20<00:13,  1.53s/it]\u001b[A\n",
            " 87% 55/63 [01:21<00:12,  1.58s/it]\u001b[A\n",
            " 89% 56/63 [01:23<00:10,  1.56s/it]\u001b[A\n",
            " 90% 57/63 [01:24<00:09,  1.52s/it]\u001b[A\n",
            " 92% 58/63 [01:26<00:07,  1.56s/it]\u001b[A\n",
            " 94% 59/63 [01:28<00:06,  1.54s/it]\u001b[A\n",
            " 95% 60/63 [01:29<00:04,  1.59s/it]\u001b[A\n",
            " 97% 61/63 [01:31<00:03,  1.59s/it]\u001b[A\n",
            " 98% 62/63 [01:32<00:01,  1.59s/it]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 748.4124755859375, 'eval_wer': 0.5216814526158693, 'eval_cer': 0.1626175335616066, 'eval_runtime': 95.8605, 'eval_samples_per_second': 5.216, 'eval_steps_per_second': 0.657, 'epoch': 0.97}\n",
            " 16% 250/1542 [36:34<1:36:23,  4.48s/it]\n",
            "100% 63/63 [01:34<00:00,  1.34s/it]\u001b[A\n",
            "{'loss': 1356.2459, 'learning_rate': 3e-05, 'epoch': 1.17}\n",
            "{'loss': 1326.6653, 'learning_rate': 3e-05, 'epoch': 1.36}\n",
            "{'loss': 1275.0577, 'learning_rate': 3e-05, 'epoch': 1.56}\n",
            "{'loss': 1301.5975, 'learning_rate': 3e-05, 'epoch': 1.75}\n",
            "{'loss': 1249.0855, 'learning_rate': 3e-05, 'epoch': 1.95}\n",
            " 32% 500/1542 [1:11:59<1:55:33,  6.65s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/63 [00:01<00:42,  1.42it/s]\u001b[A\n",
            "  5% 3/63 [00:02<01:00,  1.01s/it]\u001b[A\n",
            "  6% 4/63 [00:04<01:12,  1.23s/it]\u001b[A\n",
            "  8% 5/63 [00:06<01:18,  1.35s/it]\u001b[A\n",
            " 10% 6/63 [00:07<01:16,  1.34s/it]\u001b[A\n",
            " 11% 7/63 [00:08<01:14,  1.33s/it]\u001b[A\n",
            " 13% 8/63 [00:09<01:13,  1.34s/it]\u001b[A\n",
            " 14% 9/63 [00:11<01:13,  1.36s/it]\u001b[A\n",
            " 16% 10/63 [00:12<01:15,  1.43s/it]\u001b[A\n",
            " 17% 11/63 [00:14<01:18,  1.51s/it]\u001b[A\n",
            " 19% 12/63 [00:16<01:18,  1.54s/it]\u001b[A\n",
            " 21% 13/63 [00:17<01:18,  1.56s/it]\u001b[A\n",
            " 22% 14/63 [00:19<01:13,  1.51s/it]\u001b[A\n",
            " 24% 15/63 [00:20<01:12,  1.52s/it]\u001b[A\n",
            " 25% 16/63 [00:22<01:12,  1.53s/it]\u001b[A\n",
            " 27% 17/63 [00:23<01:09,  1.51s/it]\u001b[A\n",
            " 29% 18/63 [00:25<01:06,  1.49s/it]\u001b[A\n",
            " 30% 19/63 [00:26<01:05,  1.49s/it]\u001b[A\n",
            " 32% 20/63 [00:28<01:04,  1.51s/it]\u001b[A\n",
            " 33% 21/63 [00:29<01:04,  1.54s/it]\u001b[A\n",
            " 35% 22/63 [00:31<01:02,  1.52s/it]\u001b[A\n",
            " 37% 23/63 [00:32<00:59,  1.50s/it]\u001b[A\n",
            " 38% 24/63 [00:34<00:59,  1.51s/it]\u001b[A\n",
            " 40% 25/63 [00:35<00:57,  1.51s/it]\u001b[A\n",
            " 41% 26/63 [00:37<00:54,  1.48s/it]\u001b[A\n",
            " 43% 27/63 [00:38<00:54,  1.51s/it]\u001b[A\n",
            " 44% 28/63 [00:40<00:51,  1.48s/it]\u001b[A\n",
            " 46% 29/63 [00:41<00:51,  1.52s/it]\u001b[A\n",
            " 48% 30/63 [00:43<00:48,  1.48s/it]\u001b[A\n",
            " 49% 31/63 [00:44<00:45,  1.42s/it]\u001b[A\n",
            " 51% 32/63 [00:46<00:45,  1.47s/it]\u001b[A\n",
            " 52% 33/63 [00:47<00:44,  1.49s/it]\u001b[A\n",
            " 54% 34/63 [00:49<00:42,  1.48s/it]\u001b[A\n",
            " 56% 35/63 [00:50<00:40,  1.45s/it]\u001b[A\n",
            " 57% 36/63 [00:52<00:39,  1.45s/it]\u001b[A\n",
            " 59% 37/63 [00:53<00:37,  1.46s/it]\u001b[A\n",
            " 60% 38/63 [00:55<00:37,  1.51s/it]\u001b[A\n",
            " 62% 39/63 [00:56<00:36,  1.50s/it]\u001b[A\n",
            " 63% 40/63 [00:58<00:36,  1.57s/it]\u001b[A\n",
            " 65% 41/63 [00:59<00:34,  1.58s/it]\u001b[A\n",
            " 67% 42/63 [01:01<00:32,  1.55s/it]\u001b[A\n",
            " 68% 43/63 [01:02<00:29,  1.50s/it]\u001b[A\n",
            " 70% 44/63 [01:04<00:26,  1.42s/it]\u001b[A\n",
            " 71% 45/63 [01:05<00:26,  1.48s/it]\u001b[A\n",
            " 73% 46/63 [01:07<00:25,  1.50s/it]\u001b[A\n",
            " 75% 47/63 [01:08<00:24,  1.52s/it]\u001b[A\n",
            " 76% 48/63 [01:10<00:23,  1.57s/it]\u001b[A\n",
            " 78% 49/63 [01:11<00:21,  1.52s/it]\u001b[A\n",
            " 79% 50/63 [01:13<00:19,  1.52s/it]\u001b[A\n",
            " 81% 51/63 [01:14<00:18,  1.54s/it]\u001b[A\n",
            " 83% 52/63 [01:16<00:16,  1.54s/it]\u001b[A\n",
            " 84% 53/63 [01:18<00:15,  1.57s/it]\u001b[A\n",
            " 86% 54/63 [01:19<00:13,  1.53s/it]\u001b[A\n",
            " 87% 55/63 [01:21<00:12,  1.57s/it]\u001b[A\n",
            " 89% 56/63 [01:22<00:10,  1.55s/it]\u001b[A\n",
            " 90% 57/63 [01:24<00:09,  1.51s/it]\u001b[A\n",
            " 92% 58/63 [01:25<00:07,  1.56s/it]\u001b[A\n",
            " 94% 59/63 [01:27<00:06,  1.53s/it]\u001b[A\n",
            " 95% 60/63 [01:28<00:04,  1.57s/it]\u001b[A\n",
            " 97% 61/63 [01:30<00:03,  1.58s/it]\u001b[A\n",
            " 98% 62/63 [01:32<00:01,  1.58s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 718.85888671875, 'eval_wer': 0.5074206118895614, 'eval_cer': 0.15837817272677862, 'eval_runtime': 95.1051, 'eval_samples_per_second': 5.257, 'eval_steps_per_second': 0.662, 'epoch': 1.95}\n",
            " 32% 500/1542 [1:13:35<1:55:33,  6.65s/it]\n",
            "100% 63/63 [01:33<00:00,  1.33s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/model-cyrillic-stress/checkpoint-500\n",
            "Configuration saved in /content/model-cyrillic-stress/checkpoint-500/config.json\n",
            "Model weights saved in /content/model-cyrillic-stress/checkpoint-500/pytorch_model.bin\n",
            "{'loss': 1200.6369, 'learning_rate': 3e-05, 'epoch': 2.14}\n",
            "{'loss': 1116.907, 'learning_rate': 3e-05, 'epoch': 2.33}\n",
            "{'loss': 1094.2367, 'learning_rate': 3e-05, 'epoch': 2.53}\n",
            "{'loss': 1103.0006, 'learning_rate': 3e-05, 'epoch': 2.72}\n",
            "{'loss': 957.1041, 'learning_rate': 3e-05, 'epoch': 2.92}\n",
            " 49% 750/1542 [1:48:48<1:39:29,  7.54s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/63 [00:01<00:40,  1.49it/s]\u001b[A\n",
            "  5% 3/63 [00:02<00:58,  1.02it/s]\u001b[A\n",
            "  6% 4/63 [00:04<01:11,  1.20s/it]\u001b[A\n",
            "  8% 5/63 [00:05<01:17,  1.34s/it]\u001b[A\n",
            " 10% 6/63 [00:07<01:16,  1.35s/it]\u001b[A\n",
            " 11% 7/63 [00:08<01:15,  1.34s/it]\u001b[A\n",
            " 13% 8/63 [00:09<01:13,  1.34s/it]\u001b[A\n",
            " 14% 9/63 [00:11<01:13,  1.37s/it]\u001b[A\n",
            " 16% 10/63 [00:12<01:15,  1.43s/it]\u001b[A\n",
            " 17% 11/63 [00:14<01:17,  1.49s/it]\u001b[A\n",
            " 19% 12/63 [00:16<01:16,  1.51s/it]\u001b[A\n",
            " 21% 13/63 [00:17<01:16,  1.54s/it]\u001b[A\n",
            " 22% 14/63 [00:19<01:13,  1.51s/it]\u001b[A\n",
            " 24% 15/63 [00:20<01:13,  1.54s/it]\u001b[A\n",
            " 25% 16/63 [00:22<01:13,  1.57s/it]\u001b[A\n",
            " 27% 17/63 [00:23<01:10,  1.54s/it]\u001b[A\n",
            " 29% 18/63 [00:25<01:07,  1.51s/it]\u001b[A\n",
            " 30% 19/63 [00:26<01:06,  1.52s/it]\u001b[A\n",
            " 32% 20/63 [00:28<01:05,  1.51s/it]\u001b[A\n",
            " 33% 21/63 [00:29<01:04,  1.53s/it]\u001b[A\n",
            " 35% 22/63 [00:31<01:01,  1.51s/it]\u001b[A\n",
            " 37% 23/63 [00:32<00:59,  1.50s/it]\u001b[A\n",
            " 38% 24/63 [00:34<00:59,  1.53s/it]\u001b[A\n",
            " 40% 25/63 [00:36<00:58,  1.55s/it]\u001b[A\n",
            " 41% 26/63 [00:37<00:55,  1.51s/it]\u001b[A\n",
            " 43% 27/63 [00:39<00:54,  1.53s/it]\u001b[A\n",
            " 44% 28/63 [00:40<00:51,  1.48s/it]\u001b[A\n",
            " 46% 29/63 [00:42<00:51,  1.51s/it]\u001b[A\n",
            " 48% 30/63 [00:43<00:48,  1.47s/it]\u001b[A\n",
            " 49% 31/63 [00:44<00:45,  1.41s/it]\u001b[A\n",
            " 51% 32/63 [00:46<00:45,  1.46s/it]\u001b[A\n",
            " 52% 33/63 [00:47<00:44,  1.50s/it]\u001b[A\n",
            " 54% 34/63 [00:49<00:43,  1.50s/it]\u001b[A\n",
            " 56% 35/63 [00:50<00:41,  1.49s/it]\u001b[A\n",
            " 57% 36/63 [00:52<00:40,  1.48s/it]\u001b[A\n",
            " 59% 37/63 [00:53<00:38,  1.49s/it]\u001b[A\n",
            " 60% 38/63 [00:55<00:38,  1.52s/it]\u001b[A\n",
            " 62% 39/63 [00:56<00:35,  1.49s/it]\u001b[A\n",
            " 63% 40/63 [00:58<00:35,  1.53s/it]\u001b[A\n",
            " 65% 41/63 [00:59<00:34,  1.55s/it]\u001b[A\n",
            " 67% 42/63 [01:01<00:32,  1.53s/it]\u001b[A\n",
            " 68% 43/63 [01:02<00:29,  1.49s/it]\u001b[A\n",
            " 70% 44/63 [01:04<00:27,  1.42s/it]\u001b[A\n",
            " 71% 45/63 [01:05<00:26,  1.48s/it]\u001b[A\n",
            " 73% 46/63 [01:07<00:25,  1.50s/it]\u001b[A\n",
            " 75% 47/63 [01:08<00:24,  1.51s/it]\u001b[A\n",
            " 76% 48/63 [01:10<00:23,  1.55s/it]\u001b[A\n",
            " 78% 49/63 [01:11<00:20,  1.49s/it]\u001b[A\n",
            " 79% 50/63 [01:13<00:19,  1.49s/it]\u001b[A\n",
            " 81% 51/63 [01:14<00:18,  1.52s/it]\u001b[A\n",
            " 83% 52/63 [01:16<00:16,  1.52s/it]\u001b[A\n",
            " 84% 53/63 [01:18<00:15,  1.57s/it]\u001b[A\n",
            " 86% 54/63 [01:19<00:13,  1.52s/it]\u001b[A\n",
            " 87% 55/63 [01:21<00:12,  1.57s/it]\u001b[A\n",
            " 89% 56/63 [01:22<00:10,  1.55s/it]\u001b[A\n",
            " 90% 57/63 [01:24<00:09,  1.50s/it]\u001b[A\n",
            " 92% 58/63 [01:25<00:07,  1.53s/it]\u001b[A\n",
            " 94% 59/63 [01:27<00:05,  1.50s/it]\u001b[A\n",
            " 95% 60/63 [01:28<00:04,  1.54s/it]\u001b[A\n",
            " 97% 61/63 [01:30<00:03,  1.56s/it]\u001b[A\n",
            " 98% 62/63 [01:31<00:01,  1.58s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 749.0132446289062, 'eval_wer': 0.49614459829201557, 'eval_cer': 0.15477743355617152, 'eval_runtime': 94.8458, 'eval_samples_per_second': 5.272, 'eval_steps_per_second': 0.664, 'epoch': 2.92}\n",
            " 49% 750/1542 [1:50:23<1:39:29,  7.54s/it]\n",
            "100% 63/63 [01:33<00:00,  1.33s/it]\u001b[A\n",
            "{'loss': 906.9735, 'learning_rate': 3e-05, 'epoch': 3.11}\n",
            "{'loss': 916.3919, 'learning_rate': 3e-05, 'epoch': 3.31}\n",
            "{'loss': 947.9609, 'learning_rate': 3e-05, 'epoch': 3.5}\n",
            "{'loss': 970.1493, 'learning_rate': 3e-05, 'epoch': 3.7}\n",
            "{'loss': 931.786, 'learning_rate': 3e-05, 'epoch': 3.89}\n",
            " 65% 1000/1542 [2:25:26<1:11:15,  7.89s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/63 [00:01<00:40,  1.49it/s]\u001b[A\n",
            "  5% 3/63 [00:02<00:58,  1.02it/s]\u001b[A\n",
            "  6% 4/63 [00:04<01:11,  1.22s/it]\u001b[A\n",
            "  8% 5/63 [00:05<01:17,  1.34s/it]\u001b[A\n",
            " 10% 6/63 [00:07<01:15,  1.33s/it]\u001b[A\n",
            " 11% 7/63 [00:08<01:14,  1.33s/it]\u001b[A\n",
            " 13% 8/63 [00:09<01:13,  1.34s/it]\u001b[A\n",
            " 14% 9/63 [00:11<01:14,  1.39s/it]\u001b[A\n",
            " 16% 10/63 [00:13<01:17,  1.45s/it]\u001b[A\n",
            " 17% 11/63 [00:14<01:18,  1.52s/it]\u001b[A\n",
            " 19% 12/63 [00:16<01:18,  1.54s/it]\u001b[A\n",
            " 21% 13/63 [00:17<01:17,  1.56s/it]\u001b[A\n",
            " 22% 14/63 [00:19<01:13,  1.51s/it]\u001b[A\n",
            " 24% 15/63 [00:20<01:12,  1.52s/it]\u001b[A\n",
            " 25% 16/63 [00:22<01:12,  1.55s/it]\u001b[A\n",
            " 27% 17/63 [00:23<01:10,  1.53s/it]\u001b[A\n",
            " 29% 18/63 [00:25<01:08,  1.52s/it]\u001b[A\n",
            " 30% 19/63 [00:26<01:07,  1.53s/it]\u001b[A\n",
            " 32% 20/63 [00:28<01:06,  1.54s/it]\u001b[A\n",
            " 33% 21/63 [00:30<01:04,  1.54s/it]\u001b[A\n",
            " 35% 22/63 [00:31<01:02,  1.53s/it]\u001b[A\n",
            " 37% 23/63 [00:33<00:59,  1.50s/it]\u001b[A\n",
            " 38% 24/63 [00:34<00:59,  1.52s/it]\u001b[A\n",
            " 40% 25/63 [00:36<00:57,  1.51s/it]\u001b[A\n",
            " 41% 26/63 [00:37<00:54,  1.49s/it]\u001b[A\n",
            " 43% 27/63 [00:39<00:55,  1.53s/it]\u001b[A\n",
            " 44% 28/63 [00:40<00:52,  1.51s/it]\u001b[A\n",
            " 46% 29/63 [00:42<00:52,  1.53s/it]\u001b[A\n",
            " 48% 30/63 [00:43<00:48,  1.48s/it]\u001b[A\n",
            " 49% 31/63 [00:44<00:45,  1.41s/it]\u001b[A\n",
            " 51% 32/63 [00:46<00:45,  1.45s/it]\u001b[A\n",
            " 52% 33/63 [00:47<00:44,  1.48s/it]\u001b[A\n",
            " 54% 34/63 [00:49<00:42,  1.48s/it]\u001b[A\n",
            " 56% 35/63 [00:50<00:40,  1.44s/it]\u001b[A\n",
            " 57% 36/63 [00:52<00:39,  1.45s/it]\u001b[A\n",
            " 59% 37/63 [00:53<00:38,  1.48s/it]\u001b[A\n",
            " 60% 38/63 [00:55<00:38,  1.52s/it]\u001b[A\n",
            " 62% 39/63 [00:56<00:35,  1.49s/it]\u001b[A\n",
            " 63% 40/63 [00:58<00:35,  1.54s/it]\u001b[A\n",
            " 65% 41/63 [00:59<00:34,  1.55s/it]\u001b[A\n",
            " 67% 42/63 [01:01<00:31,  1.52s/it]\u001b[A\n",
            " 68% 43/63 [01:02<00:29,  1.48s/it]\u001b[A\n",
            " 70% 44/63 [01:04<00:26,  1.39s/it]\u001b[A\n",
            " 71% 45/63 [01:05<00:26,  1.47s/it]\u001b[A\n",
            " 73% 46/63 [01:07<00:25,  1.50s/it]\u001b[A\n",
            " 75% 47/63 [01:08<00:24,  1.53s/it]\u001b[A\n",
            " 76% 48/63 [01:10<00:23,  1.56s/it]\u001b[A\n",
            " 78% 49/63 [01:11<00:20,  1.50s/it]\u001b[A\n",
            " 79% 50/63 [01:13<00:19,  1.49s/it]\u001b[A\n",
            " 81% 51/63 [01:14<00:18,  1.52s/it]\u001b[A\n",
            " 83% 52/63 [01:16<00:16,  1.53s/it]\u001b[A\n",
            " 84% 53/63 [01:18<00:15,  1.56s/it]\u001b[A\n",
            " 86% 54/63 [01:19<00:13,  1.53s/it]\u001b[A\n",
            " 87% 55/63 [01:21<00:12,  1.60s/it]\u001b[A\n",
            " 89% 56/63 [01:22<00:11,  1.59s/it]\u001b[A\n",
            " 90% 57/63 [01:24<00:09,  1.54s/it]\u001b[A\n",
            " 92% 58/63 [01:25<00:07,  1.55s/it]\u001b[A\n",
            " 94% 59/63 [01:27<00:06,  1.52s/it]\u001b[A\n",
            " 95% 60/63 [01:28<00:04,  1.56s/it]\u001b[A\n",
            " 97% 61/63 [01:30<00:03,  1.56s/it]\u001b[A\n",
            " 98% 62/63 [01:32<00:01,  1.56s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 773.70361328125, 'eval_wer': 0.49655915761545477, 'eval_cer': 0.15530735366052503, 'eval_runtime': 95.0228, 'eval_samples_per_second': 5.262, 'eval_steps_per_second': 0.663, 'epoch': 3.89}\n",
            " 65% 1000/1542 [2:27:01<1:11:15,  7.89s/it]\n",
            "100% 63/63 [01:33<00:00,  1.33s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/model-cyrillic-stress/checkpoint-1000\n",
            "Configuration saved in /content/model-cyrillic-stress/checkpoint-1000/config.json\n",
            "Model weights saved in /content/model-cyrillic-stress/checkpoint-1000/pytorch_model.bin\n",
            "{'loss': 1224.7077, 'learning_rate': 3e-05, 'epoch': 4.09}\n",
            "{'loss': 1174.6094, 'learning_rate': 3e-05, 'epoch': 4.28}\n",
            "{'loss': 1227.997, 'learning_rate': 3e-05, 'epoch': 4.47}\n",
            "{'loss': 1164.3683, 'learning_rate': 3e-05, 'epoch': 4.67}\n",
            "{'loss': 1134.9556, 'learning_rate': 3e-05, 'epoch': 4.86}\n",
            " 81% 1250/1542 [3:02:13<47:30,  9.76s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/63 [00:01<00:42,  1.45it/s]\u001b[A\n",
            "  5% 3/63 [00:02<00:59,  1.00it/s]\u001b[A\n",
            "  6% 4/63 [00:04<01:12,  1.23s/it]\u001b[A\n",
            "  8% 5/63 [00:06<01:19,  1.36s/it]\u001b[A\n",
            " 10% 6/63 [00:07<01:17,  1.37s/it]\u001b[A\n",
            " 11% 7/63 [00:08<01:16,  1.37s/it]\u001b[A\n",
            " 13% 8/63 [00:10<01:15,  1.36s/it]\u001b[A\n",
            " 14% 9/63 [00:11<01:15,  1.39s/it]\u001b[A\n",
            " 16% 10/63 [00:13<01:17,  1.45s/it]\u001b[A\n",
            " 17% 11/63 [00:14<01:18,  1.52s/it]\u001b[A\n",
            " 19% 12/63 [00:16<01:19,  1.56s/it]\u001b[A\n",
            " 21% 13/63 [00:18<01:20,  1.60s/it]\u001b[A\n",
            " 22% 14/63 [00:19<01:16,  1.56s/it]\u001b[A\n",
            " 24% 15/63 [00:21<01:15,  1.58s/it]\u001b[A\n",
            " 25% 16/63 [00:22<01:15,  1.61s/it]\u001b[A\n",
            " 27% 17/63 [00:24<01:12,  1.59s/it]\u001b[A\n",
            " 29% 18/63 [00:25<01:10,  1.56s/it]\u001b[A\n",
            " 30% 19/63 [00:27<01:08,  1.56s/it]\u001b[A\n",
            " 32% 20/63 [00:29<01:07,  1.56s/it]\u001b[A\n",
            " 33% 21/63 [00:30<01:05,  1.57s/it]\u001b[A\n",
            " 35% 22/63 [00:32<01:04,  1.57s/it]\u001b[A\n",
            " 37% 23/63 [00:33<01:01,  1.54s/it]\u001b[A\n",
            " 38% 24/63 [00:35<01:01,  1.58s/it]\u001b[A\n",
            " 40% 25/63 [00:37<01:00,  1.60s/it]\u001b[A\n",
            " 41% 26/63 [00:38<00:57,  1.56s/it]\u001b[A\n",
            " 43% 27/63 [00:40<00:56,  1.58s/it]\u001b[A\n",
            " 44% 28/63 [00:41<00:54,  1.55s/it]\u001b[A\n",
            " 46% 29/63 [00:43<00:53,  1.56s/it]\u001b[A\n",
            " 48% 30/63 [00:44<00:50,  1.52s/it]\u001b[A\n",
            " 49% 31/63 [00:45<00:46,  1.45s/it]\u001b[A\n",
            " 51% 32/63 [00:47<00:47,  1.52s/it]\u001b[A\n",
            " 52% 33/63 [00:49<00:46,  1.56s/it]\u001b[A\n",
            " 54% 34/63 [00:50<00:45,  1.56s/it]\u001b[A\n",
            " 56% 35/63 [00:52<00:42,  1.51s/it]\u001b[A\n",
            " 57% 36/63 [00:53<00:41,  1.52s/it]\u001b[A\n",
            " 59% 37/63 [00:55<00:40,  1.54s/it]\u001b[A\n",
            " 60% 38/63 [00:57<00:39,  1.57s/it]\u001b[A\n",
            " 62% 39/63 [00:58<00:36,  1.54s/it]\u001b[A\n",
            " 63% 40/63 [01:00<00:36,  1.61s/it]\u001b[A\n",
            " 65% 41/63 [01:01<00:35,  1.62s/it]\u001b[A\n",
            " 67% 42/63 [01:03<00:33,  1.61s/it]\u001b[A\n",
            " 68% 43/63 [01:04<00:31,  1.56s/it]\u001b[A\n",
            " 70% 44/63 [01:06<00:27,  1.47s/it]\u001b[A\n",
            " 71% 45/63 [01:07<00:27,  1.54s/it]\u001b[A\n",
            " 73% 46/63 [01:09<00:26,  1.55s/it]\u001b[A\n",
            " 75% 47/63 [01:11<00:25,  1.56s/it]\u001b[A\n",
            " 76% 48/63 [01:12<00:24,  1.62s/it]\u001b[A\n",
            " 78% 49/63 [01:14<00:21,  1.56s/it]\u001b[A\n",
            " 79% 50/63 [01:15<00:20,  1.56s/it]\u001b[A\n",
            " 81% 51/63 [01:17<00:19,  1.61s/it]\u001b[A\n",
            " 83% 52/63 [01:19<00:17,  1.62s/it]\u001b[A\n",
            " 84% 53/63 [01:20<00:16,  1.63s/it]\u001b[A\n",
            " 86% 54/63 [01:22<00:14,  1.58s/it]\u001b[A\n",
            " 87% 55/63 [01:24<00:13,  1.63s/it]\u001b[A\n",
            " 89% 56/63 [01:25<00:11,  1.60s/it]\u001b[A\n",
            " 90% 57/63 [01:26<00:09,  1.55s/it]\u001b[A\n",
            " 92% 58/63 [01:28<00:07,  1.56s/it]\u001b[A\n",
            " 94% 59/63 [01:30<00:06,  1.54s/it]\u001b[A\n",
            " 95% 60/63 [01:31<00:04,  1.59s/it]\u001b[A\n",
            " 97% 61/63 [01:33<00:03,  1.62s/it]\u001b[A\n",
            " 98% 62/63 [01:35<00:01,  1.62s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 683.9775390625, 'eval_wer': 0.47508498466130505, 'eval_cer': 0.14877167237349856, 'eval_runtime': 98.0799, 'eval_samples_per_second': 5.098, 'eval_steps_per_second': 0.642, 'epoch': 4.86}\n",
            " 81% 1250/1542 [3:03:51<47:30,  9.76s/it]\n",
            "100% 63/63 [01:36<00:00,  1.37s/it]\u001b[A\n",
            "{'loss': 1120.5474, 'learning_rate': 3e-05, 'epoch': 5.06}\n",
            "{'loss': 1154.2132, 'learning_rate': 2.4630350194552528e-05, 'epoch': 5.25}\n",
            "{'loss': 1104.2977, 'learning_rate': 1.879377431906615e-05, 'epoch': 5.45}\n",
            "{'loss': 1107.8494, 'learning_rate': 1.3073929961089494e-05, 'epoch': 5.64}\n",
            "{'loss': 1082.6879, 'learning_rate': 7.2373540856031134e-06, 'epoch': 5.84}\n",
            " 97% 1500/1542 [3:38:47<06:40,  9.55s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/63 [00:01<00:40,  1.50it/s]\u001b[A\n",
            "  5% 3/63 [00:02<00:58,  1.03it/s]\u001b[A\n",
            "  6% 4/63 [00:04<01:11,  1.21s/it]\u001b[A\n",
            "  8% 5/63 [00:05<01:17,  1.34s/it]\u001b[A\n",
            " 10% 6/63 [00:07<01:15,  1.33s/it]\u001b[A\n",
            " 11% 7/63 [00:08<01:14,  1.33s/it]\u001b[A\n",
            " 13% 8/63 [00:09<01:14,  1.35s/it]\u001b[A\n",
            " 14% 9/63 [00:11<01:14,  1.39s/it]\u001b[A\n",
            " 16% 10/63 [00:13<01:17,  1.46s/it]\u001b[A\n",
            " 17% 11/63 [00:14<01:19,  1.52s/it]\u001b[A\n",
            " 19% 12/63 [00:16<01:18,  1.54s/it]\u001b[A\n",
            " 21% 13/63 [00:17<01:17,  1.56s/it]\u001b[A\n",
            " 22% 14/63 [00:19<01:13,  1.51s/it]\u001b[A\n",
            " 24% 15/63 [00:20<01:13,  1.52s/it]\u001b[A\n",
            " 25% 16/63 [00:22<01:12,  1.55s/it]\u001b[A\n",
            " 27% 17/63 [00:23<01:10,  1.54s/it]\u001b[A\n",
            " 29% 18/63 [00:25<01:08,  1.52s/it]\u001b[A\n",
            " 30% 19/63 [00:27<01:07,  1.54s/it]\u001b[A\n",
            " 32% 20/63 [00:28<01:05,  1.53s/it]\u001b[A\n",
            " 33% 21/63 [00:30<01:04,  1.55s/it]\u001b[A\n",
            " 35% 22/63 [00:31<01:02,  1.53s/it]\u001b[A\n",
            " 37% 23/63 [00:33<00:59,  1.50s/it]\u001b[A\n",
            " 38% 24/63 [00:34<00:59,  1.52s/it]\u001b[A\n",
            " 40% 25/63 [00:36<00:57,  1.52s/it]\u001b[A\n",
            " 41% 26/63 [00:37<00:55,  1.50s/it]\u001b[A\n",
            " 43% 27/63 [00:39<00:55,  1.53s/it]\u001b[A\n",
            " 44% 28/63 [00:40<00:52,  1.51s/it]\u001b[A\n",
            " 46% 29/63 [00:42<00:51,  1.53s/it]\u001b[A\n",
            " 48% 30/63 [00:43<00:48,  1.48s/it]\u001b[A\n",
            " 49% 31/63 [00:44<00:45,  1.41s/it]\u001b[A\n",
            " 51% 32/63 [00:46<00:45,  1.46s/it]\u001b[A\n",
            " 52% 33/63 [00:47<00:44,  1.48s/it]\u001b[A\n",
            " 54% 34/63 [00:49<00:43,  1.49s/it]\u001b[A\n",
            " 56% 35/63 [00:50<00:40,  1.45s/it]\u001b[A\n",
            " 57% 36/63 [00:52<00:39,  1.46s/it]\u001b[A\n",
            " 59% 37/63 [00:53<00:38,  1.48s/it]\u001b[A\n",
            " 60% 38/63 [00:55<00:38,  1.53s/it]\u001b[A\n",
            " 62% 39/63 [00:56<00:35,  1.50s/it]\u001b[A\n",
            " 63% 40/63 [00:58<00:35,  1.55s/it]\u001b[A\n",
            " 65% 41/63 [01:00<00:34,  1.55s/it]\u001b[A\n",
            " 67% 42/63 [01:01<00:31,  1.52s/it]\u001b[A\n",
            " 68% 43/63 [01:02<00:29,  1.48s/it]\u001b[A\n",
            " 70% 44/63 [01:04<00:26,  1.40s/it]\u001b[A\n",
            " 71% 45/63 [01:05<00:26,  1.48s/it]\u001b[A\n",
            " 73% 46/63 [01:07<00:25,  1.51s/it]\u001b[A\n",
            " 75% 47/63 [01:08<00:24,  1.53s/it]\u001b[A\n",
            " 76% 48/63 [01:10<00:23,  1.57s/it]\u001b[A\n",
            " 78% 49/63 [01:11<00:20,  1.50s/it]\u001b[A\n",
            " 79% 50/63 [01:13<00:19,  1.50s/it]\u001b[A\n",
            " 81% 51/63 [01:15<00:18,  1.52s/it]\u001b[A\n",
            " 83% 52/63 [01:16<00:16,  1.52s/it]\u001b[A\n",
            " 84% 53/63 [01:18<00:15,  1.55s/it]\u001b[A\n",
            " 86% 54/63 [01:19<00:13,  1.52s/it]\u001b[A\n",
            " 87% 55/63 [01:21<00:12,  1.59s/it]\u001b[A\n",
            " 89% 56/63 [01:22<00:11,  1.57s/it]\u001b[A\n",
            " 90% 57/63 [01:24<00:09,  1.52s/it]\u001b[A\n",
            " 92% 58/63 [01:25<00:07,  1.54s/it]\u001b[A\n",
            " 94% 59/63 [01:27<00:06,  1.51s/it]\u001b[A\n",
            " 95% 60/63 [01:29<00:04,  1.55s/it]\u001b[A\n",
            " 97% 61/63 [01:30<00:03,  1.55s/it]\u001b[A\n",
            " 98% 62/63 [01:32<00:01,  1.56s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 672.41064453125, 'eval_wer': 0.46812038802752676, 'eval_cer': 0.14527963476275885, 'eval_runtime': 95.0542, 'eval_samples_per_second': 5.26, 'eval_steps_per_second': 0.663, 'epoch': 5.84}\n",
            " 97% 1500/1542 [3:40:22<06:40,  9.55s/it]\n",
            "100% 63/63 [01:33<00:00,  1.32s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/model-cyrillic-stress/checkpoint-1500\n",
            "Configuration saved in /content/model-cyrillic-stress/checkpoint-1500/config.json\n",
            "Model weights saved in /content/model-cyrillic-stress/checkpoint-1500/pytorch_model.bin\n",
            "100% 1542/1542 [3:45:53<00:00,  6.77s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 13553.0684, 'train_samples_per_second': 2.731, 'train_steps_per_second': 0.114, 'train_loss': 1160.8259818822958, 'epoch': 6.0}\n",
            "100% 1542/1542 [3:45:53<00:00,  8.79s/it]\n",
            "Saving model checkpoint to /content/model-cyrillic-stress\n",
            "Configuration saved in /content/model-cyrillic-stress/config.json\n",
            "Model weights saved in /content/model-cyrillic-stress/pytorch_model.bin\n",
            "***** train metrics *****\n",
            "  epoch                    =        6.0\n",
            "  train_loss               =   1160.826\n",
            "  train_runtime            = 3:45:53.06\n",
            "  train_samples            =       6168\n",
            "  train_samples_per_second =      2.731\n",
            "  train_steps_per_second   =      0.114\n",
            "INFO:huggingsound.speech_recognition.model:Loading fine-tuned model...\n",
            "loading configuration file /content/model-cyrillic-stress/config.json\n",
            "Model config Wav2Vec2Config {\n",
            "  \"_name_or_path\": \"/content/model-cyrillic-stress\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"adapter_kernel_size\": 3,\n",
            "  \"adapter_stride\": 2,\n",
            "  \"add_adapter\": false,\n",
            "  \"apply_spec_augment\": true,\n",
            "  \"architectures\": [\n",
            "    \"Wav2Vec2ForCTC\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classifier_proj_size\": 256,\n",
            "  \"codevector_dim\": 768,\n",
            "  \"contrastive_logits_temperature\": 0.1,\n",
            "  \"conv_bias\": true,\n",
            "  \"conv_dim\": [\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512\n",
            "  ],\n",
            "  \"conv_kernel\": [\n",
            "    10,\n",
            "    3,\n",
            "    3,\n",
            "    3,\n",
            "    3,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"conv_stride\": [\n",
            "    5,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"ctc_loss_reduction\": \"sum\",\n",
            "  \"ctc_zero_infinity\": false,\n",
            "  \"diversity_loss_weight\": 0.1,\n",
            "  \"do_stable_layer_norm\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"feat_extract_activation\": \"gelu\",\n",
            "  \"feat_extract_dropout\": 0.0,\n",
            "  \"feat_extract_norm\": \"layer\",\n",
            "  \"feat_proj_dropout\": 0.1,\n",
            "  \"feat_quantizer_dropout\": 0.0,\n",
            "  \"final_dropout\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"layerdrop\": 0.0,\n",
            "  \"mask_channel_length\": 10,\n",
            "  \"mask_channel_min_space\": 1,\n",
            "  \"mask_channel_other\": 0.0,\n",
            "  \"mask_channel_prob\": 0.0,\n",
            "  \"mask_channel_selection\": \"static\",\n",
            "  \"mask_feature_length\": 10,\n",
            "  \"mask_feature_min_masks\": 0,\n",
            "  \"mask_feature_prob\": 0.0,\n",
            "  \"mask_time_length\": 10,\n",
            "  \"mask_time_min_masks\": 2,\n",
            "  \"mask_time_min_space\": 1,\n",
            "  \"mask_time_other\": 0.0,\n",
            "  \"mask_time_prob\": 0.05,\n",
            "  \"mask_time_selection\": \"static\",\n",
            "  \"model_type\": \"wav2vec2\",\n",
            "  \"num_adapter_layers\": 3,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_codevector_groups\": 2,\n",
            "  \"num_codevectors_per_group\": 320,\n",
            "  \"num_conv_pos_embedding_groups\": 16,\n",
            "  \"num_conv_pos_embeddings\": 128,\n",
            "  \"num_feat_extract_layers\": 7,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_negatives\": 100,\n",
            "  \"output_hidden_size\": 1024,\n",
            "  \"pad_token_id\": 33,\n",
            "  \"proj_codevector_dim\": 768,\n",
            "  \"tdnn_dilation\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    1,\n",
            "    1\n",
            "  ],\n",
            "  \"tdnn_dim\": [\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    1500\n",
            "  ],\n",
            "  \"tdnn_kernel\": [\n",
            "    5,\n",
            "    3,\n",
            "    3,\n",
            "    1,\n",
            "    1\n",
            "  ],\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_weighted_layer_sum\": false,\n",
            "  \"vocab_size\": 38,\n",
            "  \"xvector_output_dim\": 512\n",
            "}\n",
            "\n",
            "loading weights file /content/model-cyrillic-stress/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing Wav2Vec2ForCTC.\n",
            "\n",
            "All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at /content/model-cyrillic-stress.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.\n",
            "loading configuration file /content/model-cyrillic-stress/preprocessor_config.json\n",
            "Feature extractor Wav2Vec2FeatureExtractor {\n",
            "  \"do_normalize\": true,\n",
            "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
            "  \"feature_size\": 1,\n",
            "  \"padding_side\": \"right\",\n",
            "  \"padding_value\": 0,\n",
            "  \"processor_class\": \"Wav2Vec2Processor\",\n",
            "  \"return_attention_mask\": true,\n",
            "  \"sampling_rate\": 16000\n",
            "}\n",
            "\n",
            "loading file vocab.json\n",
            "loading file tokenizer_config.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "!python $TRAINING_PATH --config colab.yaml --num_train_epochs 6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyBHsKv7NHnp",
        "outputId": "a2de222f-c033-4f92-880c-864fe460413b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.path.exists('/content/drive/MyDrive/RussianNationalCorpus/big_data/media/karyagina_empatiya_031.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ohpQupPbA8S",
        "outputId": "aaac8c7f-3a4c-4649-93e8-4ab4f96e041a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-02-22 21:30:41.348960: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-22 21:30:42.238394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-22 21:30:42.238508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-22 21:30:42.238519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "INFO:huggingsound.speech_recognition.model:Loading model...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StressDetection/evaluate_model.py\", line 54, in <module>\n",
            "    if preds.is_file():\n",
            "NameError: name 'preds' is not defined\n"
          ]
        }
      ],
      "source": [
        "!python $EVALUATION_PATH --config colab.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "N3D5it8cnB00",
        "outputId": "a30faaaf-d465-4c1f-a8fe-716108e6a765"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d13ce59f8033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-cyrillic-stress/pytorch_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-cyrillic-stress/config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-cyrillic-stress/checkpoint-2500/pytorch_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-cyrillic-stress/checkpoint-2500/config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ],
      "source": [
        "files.download('/content/model-cyrillic-stress/pytorch_model.bin') \n",
        "files.download('/content/model-cyrillic-stress/config.json') \n",
        "files.download('/content/model-cyrillic-stress/checkpoint-2500/pytorch_model.bin') \n",
        "files.download('/content/model-cyrillic-stress/checkpoint-2500/config.json') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSbw6VIzaZJt"
      },
      "source": [
        "# Evaluate the model\n",
        "Run first the --help command to learn which arguments you should provide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy3hk7wuviTP",
        "outputId": "f293ffe1-7d8a-4ad6-c160-18184ed102b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
            "Options and arguments (and corresponding environment variables):\n",
            "-b     : issue warnings about str(bytes_instance), str(bytearray_instance)\n",
            "         and comparing bytes/bytearray with str. (-bb: issue errors)\n",
            "-B     : don't write .pyc files on import; also PYTHONDONTWRITEBYTECODE=x\n",
            "-c cmd : program passed in as string (terminates option list)\n",
            "-d     : debug output from parser; also PYTHONDEBUG=x\n",
            "-E     : ignore PYTHON* environment variables (such as PYTHONPATH)\n",
            "-h     : print this help message and exit (also --help)\n",
            "-i     : inspect interactively after running script; forces a prompt even\n",
            "         if stdin does not appear to be a terminal; also PYTHONINSPECT=x\n",
            "-I     : isolate Python from the user's environment (implies -E and -s)\n",
            "-m mod : run library module as a script (terminates option list)\n",
            "-O     : remove assert and __debug__-dependent statements; add .opt-1 before\n",
            "         .pyc extension; also PYTHONOPTIMIZE=x\n",
            "-OO    : do -O changes and also discard docstrings; add .opt-2 before\n",
            "         .pyc extension\n",
            "-q     : don't print version and copyright messages on interactive startup\n",
            "-s     : don't add user site directory to sys.path; also PYTHONNOUSERSITE\n",
            "-S     : don't imply 'import site' on initialization\n",
            "-u     : force the stdout and stderr streams to be unbuffered;\n",
            "         this option has no effect on stdin; also PYTHONUNBUFFERED=x\n",
            "-v     : verbose (trace import statements); also PYTHONVERBOSE=x\n",
            "         can be supplied multiple times to increase verbosity\n",
            "-V     : print the Python version number and exit (also --version)\n",
            "         when given twice, print more information about the build\n",
            "-W arg : warning control; arg is action:message:category:module:lineno\n",
            "         also PYTHONWARNINGS=arg\n",
            "-x     : skip first line of source, allowing use of non-Unix forms of #!cmd\n",
            "-X opt : set implementation-specific option. The following options are available:\n",
            "\n",
            "         -X faulthandler: enable faulthandler\n",
            "         -X showrefcount: output the total reference count and number of used\n",
            "             memory blocks when the program finishes or after each statement in the\n",
            "             interactive interpreter. This only works on debug builds\n",
            "         -X tracemalloc: start tracing Python memory allocations using the\n",
            "             tracemalloc module. By default, only the most recent frame is stored in a\n",
            "             traceback of a trace. Use -X tracemalloc=NFRAME to start tracing with a\n",
            "             traceback limit of NFRAME frames\n",
            "         -X showalloccount: output the total count of allocated objects for each\n",
            "             type when the program finishes. This only works when Python was built with\n",
            "             COUNT_ALLOCS defined\n",
            "         -X importtime: show how long each import takes. It shows module name,\n",
            "             cumulative time (including nested imports) and self time (excluding\n",
            "             nested imports). Note that its output may be broken in multi-threaded\n",
            "             application. Typical usage is python3 -X importtime -c 'import asyncio'\n",
            "         -X dev: enable CPython's \"development mode\", introducing additional runtime\n",
            "             checks which are too expensive to be enabled by default. Effect of the\n",
            "             developer mode:\n",
            "                * Add default warning filter, as -W default\n",
            "                * Install debug hooks on memory allocators: see the PyMem_SetupDebugHooks() C function\n",
            "                * Enable the faulthandler module to dump the Python traceback on a crash\n",
            "                * Enable asyncio debug mode\n",
            "                * Set the dev_mode attribute of sys.flags to True\n",
            "                * io.IOBase destructor logs close() exceptions\n",
            "         -X utf8: enable UTF-8 mode for operating system interfaces, overriding the default\n",
            "             locale-aware mode. -X utf8=0 explicitly disables UTF-8 mode (even when it would\n",
            "             otherwise activate automatically)\n",
            "         -X pycache_prefix=PATH: enable writing .pyc files to a parallel tree rooted at the\n",
            "             given directory instead of to the code tree\n",
            "\n",
            "--check-hash-based-pycs always|default|never:\n",
            "    control how Python invalidates hash-based .pyc files\n",
            "file   : program read from script file\n",
            "-      : program read from stdin (default; interactive mode if a tty)\n",
            "arg ...: arguments passed to program in sys.argv[1:]\n",
            "\n",
            "Other environment variables:\n",
            "PYTHONSTARTUP: file executed on interactive startup (no default)\n",
            "PYTHONPATH   : ':'-separated list of directories prefixed to the\n",
            "               default module search path.  The result is sys.path.\n",
            "PYTHONHOME   : alternate <prefix> directory (or <prefix>:<exec_prefix>).\n",
            "               The default module search path uses <prefix>/lib/pythonX.X.\n",
            "PYTHONCASEOK : ignore case in 'import' statements (Windows).\n",
            "PYTHONUTF8: if set to 1, enable the UTF-8 mode.\n",
            "PYTHONIOENCODING: Encoding[:errors] used for stdin/stdout/stderr.\n",
            "PYTHONFAULTHANDLER: dump the Python traceback on fatal errors.\n",
            "PYTHONHASHSEED: if this variable is set to 'random', a random value is used\n",
            "   to seed the hashes of str and bytes objects.  It can also be set to an\n",
            "   integer in the range [0,4294967295] to get hash values with a\n",
            "   predictable seed.\n",
            "PYTHONMALLOC: set the Python memory allocators and/or install debug hooks\n",
            "   on Python memory allocators. Use PYTHONMALLOC=debug to install debug\n",
            "   hooks.\n",
            "PYTHONCOERCECLOCALE: if this variable is set to 0, it disables the locale\n",
            "   coercion behavior. Use PYTHONCOERCECLOCALE=warn to request display of\n",
            "   locale coercion and locale compatibility warnings on stderr.\n",
            "PYTHONBREAKPOINT: if this variable is set to 0, it disables the default\n",
            "   debugger. It can be set to the callable of your debugger of choice.\n",
            "PYTHONDEVMODE: enable the development mode.\n",
            "PYTHONPYCACHEPREFIX: root directory for bytecode cache (pyc) files.\n"
          ]
        }
      ],
      "source": [
        "!python $EVALUATION_PATH --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMwDGSdfaYWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d56f7d1-8ec0-4837-a609-1fe63041890b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-24 05:30:26.291206: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-24 05:30:27.146357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-24 05:30:27.146467: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-24 05:30:27.146486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "INFO:huggingsound.speech_recognition.model:Loading model...\n",
            "Is preds a file? False\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StressDetection/evaluate_model.py\", line 81, in <module>\n",
            "    with open(preds, 'r') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/StressDetection/results/transcriptions_new_stressed_soft.json'\n"
          ]
        }
      ],
      "source": [
        "!python $EVALUATION_PATH --config colab.yaml"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}