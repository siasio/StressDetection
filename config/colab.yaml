data:
  dir: '/content/drive/MyDrive/RussianNationalCorpus/big_data'
  examples: 'train_data.csv'
  helper: 'helper.csv'
  eval: 'eval_data.csv'
  examples_per_query: 'examples'
  media: 'media'
  cache: 'cache'
  use_mp3: no  # Files are downloaded as .mp4. However, this sometimes causes errors and a conversion to .mp3 is needed.

query:
  pages_per_query: 5  # By default, each page contains 5 examples
  seconds_threshold: 15
  keep_only_one_person: yes
  one_sample_per_video: no

training:
  # We can take either a fine-tuned or only pretrained model from the web.
  # Note that for a fine-tuned model a token set is already defined.
  web_model: 'facebook/wav2vec2-large-xlsr-53'  # a large model trained on 53 languages from the common_voice dataset
  pretrained_model_folder: '/content/drive/MyDrive/RussianNationalCorpus/model-cyrillic'
  output_model_folder: '/content/drive/MyDrive/RussianNationalCorpus/model-cyrillic'
  use_model_from_web: no
  batch_size: 24
  fp16: yes
  logging_steps: 50
  eval_steps: 250
